<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <title>Chat AI Assistant DEMO</title>
        <meta name="apple-mobile-web-app-capable" content="yes" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />
        <meta name="apple-mobile-web-app-status-bar-style" content="black" />

        <link rel="shortcut icon" href="favicon.ico">
    
        <link rel="stylesheet" href="flat-ui/bootstrap/css/bootstrap.css">
        <link rel="stylesheet" href="flat-ui/css/flat-ui.css">
        
        <!-- Using only with Flat-UI (free)-->
        <link rel="stylesheet" href="common-files/css/icon-font.css">

        <link rel="stylesheet" href="common-files/css/animations.css">
        
        <!-- If you don't use any of these blocks just remove unnecessary CSS files -->
        <!-- blog -->
        <link rel="stylesheet" href="ui-kit/ui-kit-blog/css/style.css">
        <!-- contacts -->
        <link rel="stylesheet" href="ui-kit/ui-kit-contacts/css/style.css">
        <!-- content -->
        <link rel="stylesheet" href="ui-kit/ui-kit-content/css/style.css">
        <!-- crew -->
        <!-- 
        <link rel="stylesheet" href="/ui-kit/ui-kit-crew/css/style.css">
         -->
        <!-- footer -->
        <link rel="stylesheet" href="ui-kit/ui-kit-footer/css/style.css">
        <!-- header -->
        <link rel="stylesheet" href="ui-kit/ui-kit-header/css/style.css">
        <!-- price -->
        <link rel="stylesheet" href="ui-kit/ui-kit-price/css/style.css">
        <!-- projects -->
        <!-- 
        <link rel="stylesheet" href="/ui-kit/ui-kit-projects/css/style.css">
         -->

        <link rel="stylesheet" href="css/style.css">
        
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-VBXT5RXRV2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-VBXT5RXRV2');
</script>        
	
<script type="text/javascript" src="common-files/js/jquery-1.10.2.min.js"></script>
		        
<style> body { margin: 0; } </style>

<style>
.switch {
  position: relative;
  display: inline-block;
  width: 60px;
  height: 34px;
}

.switch input { 
  opacity: 0;
  width: 0;
  height: 0;
}

.slider {
  position: absolute;
  cursor: pointer;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background-color: #ccc;
  -webkit-transition: .4s;
  transition: .4s;
}

.slider:before {
  position: absolute;
  content: "";
  height: 26px;
  width: 26px;
  left: 4px;
  bottom: 4px;
  background-color: white;
  -webkit-transition: .4s;
  transition: .4s;
}

input:checked + .slider {
  background-color: #2196F3;
}

input:focus + .slider {
  box-shadow: 0 0 1px #2196F3;
}

input:checked + .slider:before {
  -webkit-transform: translateX(26px);
  -ms-transform: translateX(26px);
  transform: translateX(26px);
}

/* Rounded sliders */
.slider.round {
  border-radius: 34px;
}

.slider.round:before {
  border-radius: 50%;
}
        
</style>          
              
</head>

<body>
   
    
<script src="https://cdnjs.cloudflare.com/ajax/libs/RecordRTC/5.6.2/RecordRTC.js"></script>
    
<script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@ricky0123/vad-web@0.0.7/dist/bundle.min.js"></script>

    
    <div class="page-wrapper">   

    <a name="demo"></a>
            
    <header class="header-1">
        <div class="container">
        <div class="row">
        <div class="navbar col-sm-12 navbar-fixed-top" role="navigation">
        <div class="navbar-header">
        <button type="button" class="navbar-toggle"></button>
        <a class="brand" target=_blank href="https://www.chat.ai">
        <img src="img/chat-ai-logo-white-transparent.png" style="height: 50px;" alt="">
        </a>
        </div>
        <div class="navbar-collapse collapse">
        <ul class="nav pull-right">
        <li>
        <a target=_blank href="https://www.chat.ai">HOME</a>
        </li>
                                                  
        <li>
        <a href="#demo">DEMO</a>
        </li>
           
        <li>
        <a href="#contact">CONTACT</a>
        </li>
         
        </ul>
            
        <ul class="subnav">
               
        </ul>
        </div>
        </div>
        </div>
        </div>
    </header>
      
    <!-- needed for top menu to be overtop content -->    
    <section class="header-1-sub bg-midnight-blue" style="height: 0px">
        
    <div id="pt-main" class="page-transitions pt-perspective">
            
    <div class="background">&nbsp;</div>
    <div class="container" style="padding-top: 165px;">
    <div class="row">
              
    <div class="col-md-12" align="center">
        <h3>&nbsp;</h3>
        <p></p><br>              
    </div> 
    </div>
    </div>
    </div>
    </section>
          
    <section class="content-21 bg-midnight-blue">
    
    <div class="container">
        
    <h2>Assistant DEMO</h2>
        
    <div class="row">
        <div class="col-sm-10 col-sm-offset-1">
        <div class="features features-tabs">
            
        <div class="features-header">
            
        <div class="box active">
            <div class="fui-bubble"></div>
            Chat with A.I. Assistant
        </div>
            
        </div>
            
        <div class="features-bodies">
            
        <div class="features-body active">
            <h6>Chat with the A.I. Assistant</h6>
            
            <div align="center">
                <h6>Listen &amp; Speak On/Off</h6>
                <label class="switch">
                    <input type="checkbox">
                    <span class="slider round"></span>
                </label>
           
            <p>Chat with powerful A.I. models.
            </p>           
                   
            <p><br><br>
            </p>   
                
            </div>
                
        </div>

        </div>
        </div>
        </div>
    </div>
    </div>
    </section>        
      
<section class="content-36 bg-midnight-blue">
    <div class="container">
    &nbsp;
    </div>
</section>
            
<a name="about"></a>
        
<section class="content-6 v-center">
    <div>
        <div class="container">
            <h3><img src="img/chat_ai_logo_black_transparent.png" width="300" alt="">Chat.AI is a service of Vital.AI which utilizes the Haley.AI platform.</h3>
            
            <div class="row features">
                <div class="col-sm-4 col-sm-offset-2">
                    <h6>Chat.ai</h6>
                    <p>Chat.ai provides end users, such as yourself, access to A.I. Assistants and A.I. Automation.</p>
                </div>
                <div class="col-sm-4 col-sm-offset-1">
                    <h6>Haley.ai</h6>
                    <p>Haley.ai is a platform for creating applications using A.I. Information is available at: <a target=_blank href=https://www.haley.ai> <font color="#46a5e4">https://www.haley.ai</font></a></p>
                </div>
            </div>
            <div class="row features">
                <div class="col-sm-4 col-sm-offset-2">
                    <h6>Vital.ai</h6>
                    <p>Vital.ai is the developer of the Haley.ai platform and operates Chat.ai.   Information is available at: <a target=_blank href=https://www.vital.ai> <font color="#46a5e4">https://www.vital.ai</font></a></p>
                </div>
            </div>
            
        </div>
    </div>
</section>            
      
<a name="contact"></a>
          
      <section class="contacts-2">
        <div class="container">
          <div class="row">
            <div class="col-sm-8">
              <h3>Contact Us</h3>
            </div>
          </div>
          <div class="row">
            <div class="col-sm-6">
                <h6>Get in touch:</h6>
                <div class="links">
                    <a href="tel:1-917-463-4776"><span class="fui-phone"></span>1.917.463.4776</a><br>
                    <a href="mailto:info@vital.ai"><span class="fui-mail"></span>info@vital.ai</a><br>
                    <a target="_blank" href="http://vital.ai"><span class="fui-link"></span>http://vital.ai</a><br>
                    <a target="_blank" href="https://blog.vital.ai"><span class="fui-link"></span>Blog https://blog.vital.ai</a>
                </div>
            </div>
            <div class="col-sm-5 col-sm-offset-1">
              <h6>We are located at:</h6>
              <p>155 Water Street<br>
                Brooklyn, NY 11201</p>
              <div class="map">
                  
                <iframe width="100%" height="100%" frameborder="0" scrolling="no" marginheight="0" marginwidth="0" src="https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d3024.667899926605!2d-73.9878342!3d40.7033112!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x89c25a33ceef3e5b%3A0x534e94c597a146f7!2s155%20Water%20St%2C%20Brooklyn%2C%20NY%2011201!5e0!3m2!1sen!2sus!4v1670877100950!5m2!1sen!2sus" style="border:0;" allowfullscreen="" loading="lazy" referrerpolicy="no-referrer-when-downgrade"></iframe>  
                                    
              </div>

            </div>
          </div>
        </div>
      </section>

	<footer class="footer-10">
    	<div class="container">
        <div class="row">
            <div class="col-sm-3">
            	
            	<nav>
            		<h6>Chat AI</h6>
            		<ul>
            			<li><a target=_blank href="https://www.chat.ai">Home</a></li>
                        <li><a href="#demo">DEMO</a></li>
            			<li><a href="#contact">Contact</a></li>
            			
            		</ul>
            	</nav>
            </div>
            <div class="col-sm-3 col-sm-offset-1">
                <nav>
                    <h6>Haley AI</h6>
                    <ul>
                        <li><a target="_blank" href="https://www.haley.ai/">Haley.ai</a></li>  
                    </ul>
                </nav>
            </div>

            <div class="col-sm-3 col-sm-offset-2">
                <nav>
                    <h6>Vital AI</h6>
                    <ul>
                        <li><a target="_blank" href="https://www.vital.ai/">Vital.ai</a></li>
                        
                    </ul>
                </nav>
            </div>
        </div>
            
        <div style="text-align: center;"> Copyright © 2024 Vital AI, LLC </div>
 
    </div>
    
</footer>
        
</div>
  
 
<script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>

<script>
/*
function float32ToInt16(buffer) {
    let int16Buffer = new Int16Array(buffer.length);
    for (let i = 0; i < buffer.length; i++) {
        int16Buffer[i] = Math.max(-1, Math.min(1, buffer[i])) * 0x7FFF;
    }
    return int16Buffer;
}
*/
    
function float32ToInt16(buffer) {
    let int16Buffer = new Uint16Array(buffer.length);
    for (let i = 0; i < buffer.length; i++) {
        int16Buffer[i] = Math.max(-32768, Math.min(32767, buffer[i] * 32768));
    }
    return int16Buffer;
}    
    
    
function float32ToNormalized(buffer) {
    
    let float32Buffer = new Float32Array(buffer.length);
    
    console.log(buffer);
    
    for (let i = 0; i < buffer.length; i++) {
        
        // float32Buffer[i] = Math.max(-32768, Math.min(32767, buffer[i] * 32768));
        
        // float32Buffer[i] = buffer[i];
        
        float32Buffer[i] = Math.round( buffer[i] * 32767 );
        float32Buffer[i] = Math.max(-32768, Math.min(32767, float32Buffer[i]));
        
    }
    
    console.log(float32Buffer);

    return float32Buffer;
}      
    
 
    
    
  function segmentAndReshapeAudioData(audioData) {
      
    const segmentSize = 16 * 96;
      
    const numSegments = Math.ceil(audioData.length / segmentSize);
    
    const reshapedSegments = [];

    for (let i = 0; i < numSegments; i++) {
        // Extract segment
        const start = i * segmentSize;
        const end = start + segmentSize;
        let segment = audioData.slice(start, end);

        // Pad the segment with zeros if necessary
        
        if (segment.length < segmentSize) {
            
            segment = new Float32Array([...segment, ...new Float32Array(segmentSize - 
            segment.length)]);
        }
        
        
        reshapedSegments.push(segment);
    }

    return reshapedSegments;
}
  
function squeezeArray(array) {
    let result = array;
    
    while (result.length === 1 && Array.isArray(result[0])) {
        result = result[0];
    }
    
    return result;
}
    
async function embeddingModelPredict(x) {
    
    const session = await ort.InferenceSession.create('./models/embedding_model.onnx');

    return session.run({ input_1: x }).then(output => {
        
        const outputTensor = output[Object.keys(output)[0]];
        
        const tensorArray = outputTensor.toArray();
        
        const squeezed = squeezeArray(tensorArray);

        return squeezed;
    });
    
}
    

async function melspecModelPredict(x) {
    
    const session = await ort.InferenceSession.create('./models/melspectrogram.onnx');

    const tensor = new ort.Tensor('float32', new Float32Array(x), [1, x.length]);
    
    return session.run({ input: tensor }).then(output => {
        
        const outputTensor = output[Object.keys(output)];
        
        return outputTensor;
    });
    
}
        

async function wakeWordPredict(x) {
    
    const session = await ort.InferenceSession.create('./models/hey_haley.onnx');

    const inputTensor = new ort.Tensor('float32', x, [1, 16, 96]);

    const outputMap = await session.run({ 'onnx::Flatten_0': inputTensor });

    return outputMap;
}
                                       
                                    
    
async function predictWithONNX(audioData) {
    
    const session = await ort.InferenceSession.create('./models/hey_haley.onnx');
    
  // const batchedAudioData = new Float32Array(audioData.length);
  // batchedAudioData.set(audioData);
  // const inputTensor = new ort.Tensor('float32', batchedAudioData, [1, audioData.length, 1]);


    //const int16AudioData = float32ToInt16(audioData);

    const normalizedData = float32ToNormalized(audioData);
    
    const audioSegments = segmentAndReshapeAudioData(normalizedData);

    for (const segment of audioSegments) {

        // const inputTensor = new ort.Tensor(segment, 'int16', [1, 16, 96]);
        
        const inputTensor = new ort.Tensor('float32', segment, [1, 16, 96]);

        const outputMap = await session.run({ 'onnx::Flatten_0': inputTensor });

        // const outputTensor = outputMap.values().next().value;

        console.log(outputMap);
            
        var output = outputMap['39'];
        
        // console.log('39: ', output);
        
        var cpuData = output['cpuData'];
        
        var score = cpuData[0];
        
        // console.log('Score: ', score);
        
        if(score > 0.5) {
            
            console.log('Wake Word Detected Score: ', score);
        }
        
        // console.log(outputTensor);

    }
            
    return [];
    
  // const inputTensor = reshapeAudioForModel(audioData);
        
  // const feeds = { 'onnx::Flatten_0': inputTensor };

  // const inputTensor = new ort.Tensor('float32', audioData, [1, audioData.length]);
  // const feeds = { 'onnx::Flatten_0': inputTensor };
  
  // const results = await session.run(feeds);
 //  return results;
}    
   
    
</script>
   
    
<script type="module">

import { loadPyodide } from 'https://cdn.jsdelivr.net/pyodide/v0.18.1/full/pyodide.mjs';

async function loadPyodideAndRunPython() {
        
    let pyodide = await loadPyodide({
        indexURL : "https://cdn.jsdelivr.net/pyodide/v0.18.1/full/"
    });
    
    await pyodide.loadPackage('numpy');
    
    await pyodide.loadPackage('micropip');
        
    await pyodide.runPythonAsync(`
        import micropip
        await micropip.install('cmudict')
    `);
    
    // Define a function to load and run a Python file
    async function loadPythonFile(pyodide, filePath) {
      const response = await fetch(filePath);
      const pythonCode = await response.text();
      pyodide.runPython(pythonCode);
    }

    await loadPythonFile(pyodide, './python/vad.py');

    await loadPythonFile(pyodide, './python/pronouncing.py');

    await loadPythonFile(pyodide, './python/init.py');

    await loadPythonFile(pyodide, './python/data.py');

    await loadPythonFile(pyodide, './python/utils.py');

    await loadPythonFile(pyodide, './python/model.py');
    
    let wakeWordModel = pyodide.runPython(`

      model_path = './models/hey_haley.onnx'
      
      inference_framework = 'onnx'

      owwModel = Model(wakeword_models=[model_path], inference_framework=inference_framework)

      owwModel
    `);
    
     console.log(wakeWordModel);
    
    window.wakeWordModel = wakeWordModel;
    
    
  }

loadPyodideAndRunPython().catch(console.error);
        
</script>    
    
<script>
   
window.whisper_worker = null;

window.whisper_worker_busy = false;

let whisper_worker_error_count = 0;
    
function create_whisper_worker(){
    
	console.log("in create_whisper_worker");
	
	window.whisper_worker = null;
	
    window.whisper_worker = new Worker('./js/whisper_worker.js', {
	  type: 'module'
	});

	console.log("whisper_module: window.whisper_worker: ", window.whisper_worker);
	
	window.whisper_worker.addEventListener('message', e => {
		
        //console.log("whisper_module: received message from whisper_worker: ", e.data);
        
		if(typeof e.data.status == 'string'){
            
			if(e.data.status == 'progress'){
				
                // console.log("whisper worker sent download percentage: ", e.data.progress);
				
                // let whisper_progress_el = document.getElementById('download-progress-whisper');
				/*
                if(whisper_progress_el == null){
					console.error("whisper (down)load progress element is missing");
					// add_chat_message("whisper",'download_progress#setting---');
				}
				else{
					//console.log("updating whisper (down)load progress");
					whisper_progress_el.value = e.data.progress / 100;
				}
                */
                
				
			}
			else if(e.data.status == 'ready'){
				console.log("whisper worker sent ready message");
				window.whisper_worker_busy = false;
                
				// add_chat_message("whisper",get_translation('Voice_recognition_has_loaded'));
				
                // let whisper_progress_el = document.getElementById('download-progress-whisper');
				
                /*
                if(whisper_progress_el){
					whisper_progress_el.classList.add('download-complete-chat-message');
				}
				else{
					console.error("whisper became ready, but cannot find loading progress indicator element");
				}
                */
                
                
			}
			else if(e.data.status == 'initiate'){
				console.log("whisper worker sent initiate message");
			}
			else if(e.data.status == 'download'){
				console.log("whisper worker sent download message");
				// add_chat_message("whisper","(down)loading: " + e.data.file);
			}
			
			else if(e.data.status == 'update'){
				if(typeof e.data.data == 'object' && e.data.data != null && e.data.data.length){
					// set_chat_status(e.data.data[0],2);
				}
				
			}
			
			else if(e.data.status == 'complete'){
				window.whisper_worker_busy = false;
				console.log('GOT WHISPER COMPLETE.  e.data: ', e.data);
				console.log('GOT WHISPER COMPLETE.  e.data.transcript: ', e.data.transcript);
				console.log('GOT WHISPER COMPLETE.  e.data.task: ', e.data.task);
				
				if(e.data.transcript == null){
					console.warn("whisper recognition failed. If this is the first run, that's normal.");
					// set_state(LISTENING);
				}
				else if(typeof e.data.transcript != 'undefined'){
					console.log("whisper returned transcription text: ", e.data.transcript);
					
					if(Array.isArray(e.data.transcript)){
						console.log("typeof transcription is array");
					}
					else if(typeof e.data.transcript == 'object'){
						if(typeof e.data.transcript.text == 'string'){
							console.log("GOT TEXT: ", e.data.transcript.text);
						}
					}
				}
				else{
					console.log("transcript was not in whisper e.data");
				}
				
				// add_chat_message("whisper","(down)loading: " + e.data.file);
			}
			else{
				console.log("whisper worker sent a content message");
				window.whisper_worker_busy = false;
				
				if(e.data.data == null){
					console.warn("whisper recognition failed. If this is the first run, that's normal.");
					// set_state(LISTENING);
				}
			}
		}
			
			if(window.enable_microphone == false){
				console.log("whisper worker returned audio file, but in the meantime enable_microphone was disabled. Throwing away the data.");
			}
			else{
				
				/*
			
				if(window.whisper_queue.length){
					console.log("whisper worker done, but there is more work to do. Sentences still in whisper_queue: ", window.whisper_queue.length);
					let next_sentence = window.whisper_queue[0][0] + window.whisper_queue[0][1]; // sentence plus punctuation mark
					window.whisper_queue.splice(0,1);
				
				
					whisper_worker.postMessage({'whisper_counter':window.whisper_counter,'sentence':next_sentence});
					window.whisper_counter++;
				}
				else{
					console.log("whisper worker was done, and there are no more sentences in the whisper queue. Worker is now idle.");
					window.whisper_worker_busy = false;
				}
				*/
			}
	
	});


	window.whisper_worker.addEventListener('error', (error) => {
		console.error("ERROR: whisper_worker sent error. terminating!. Error was: ", error, error.message);
		whisper_worker_error_count++;
		
		window.whisper_worker.terminate();
		window.whisper_worker_busy = false;
		if(typeof error != 'undefined' && whisper_worker_error_count < 10){
			setTimeout(() => {
				console.log("attempting to restart whisper worker");
				create_whisper_worker();
			},1000);
		}
		else{
			console.error("whisper_worker errored out");
		}
	});
}

// create whisper worker
create_whisper_worker();


//
//  Send audio buffer to whisper worker
//
function do_whisper_web(task,language=null){
	console.log("in do_whisper_web. task: ", task);
	
	if(window.whisper_worker_busy){
		console.error("do_whisper_web was called while whisper worker was busy. Aborting.");
		return
	}
	
	if(typeof task.recorded_audio == 'undefined'){
		console.error("do_whisper_web: task did not contain recorded_audio. Aborting.");
		return
	}
	
	task.state == 'stt_in_progress';
	
	let multilingual = false;
    
	if(typeof language == 'string'){
		if(language != 'en'){
			multilingual = true;
		}
	}
    
	const quantized = false;
	
    const model = "Xenova/whisper-tiny";
	
	const subtask = null;
	
	console.log("do_whisper_web: sending audio to whisper worker: ", task.recorded_audio);
	
    window.whisper_worker.postMessage({
        task:task,
        model,
        multilingual,
        quantized,
        subtask: multilingual ? subtask : null,
        language:
            multilingual && language !== "auto" ? language : null,
    });

}
window.do_whisper_web = do_whisper_web;
    
    
</script>    
    
    
<script>
    
  var myvad = null;    
    
  async function main() {
      
    myvad = await vad.MicVAD.new({
        
      onSpeechStart: () => {
        console.log("Speech start detected")
      },
        
      onSpeechEnd: (audio) => {
          
        console.log("Speech end detected")

          
        // do something with `audio` (Float32Array of audio samples at sample rate 16000)...
          
          
        // predictWithONNX(audio);
          
        var task = {};
        
        task.recorded_audio = audio;
          
        do_whisper_web(task);
          
      },
        
        onFrameProcessed: (probabilities) => {
            
            // {isSpeech: float; notSpeech: float}
            
            let isSpeech = probabilities.isSpeech;
            
            let notSpeech = probabilities.notSpeech;
            
            // var wakeWordModel = window.wakeWordModel;
            
            // wakeWordModel.vad.append(isSpeech);
            
            if(isSpeech > 0.1) {
                // console.log("Is Speech: ", isSpeech);
            }
        } 
        
    })
  }
    
  main();
    
  
let audioBuffer = [];
let sampleRate = 16000;
let desiredSampleCount = 1280;
let microphone;
let recorder; 
    
    
    
    
</script>    
    
    
<script>
        
document.addEventListener('DOMContentLoaded', function () {
    
  var checkbox = document.querySelector('input[type="checkbox"]');

  checkbox.addEventListener('change', function () {
    
    if (checkbox.checked) {
     
      console.log('Checked');
    
        myvad.start()
        
        
        navigator.mediaDevices.getUserMedia({ audio: true })
            .then(function(stream) {
    
                microphone = stream;
            /*
                recorder = RecordRTC(microphone, {
    type: 'audio',
    //mimeType: 'audio/wav',
    desiredSampRate: sampleRate,
    timeSlice: 40,
    ondataavailable: function(blob) {
        
        //  && blob.type === 'audio/wav'
        if (blob.size > 0) {
        
        console.log('Received blob is valid');
    
        let audioContext = new (window.AudioContext || window.webkitAudioContext)();
        
        let reader = new FileReader();
        
        reader.onload = function() {
            
            audioContext.decodeAudioData(reader.result, function(buffer) {
                
                let samples = buffer.getChannelData(0);
                
                audioBuffer = audioBuffer.concat(Array.from(samples));
                
                if (audioBuffer.length >= desiredSampleCount) {
                    
                    console.log(`Processing ${desiredSampleCount} samples`);

                    audioBuffer = audioBuffer.slice(desiredSampleCount);
                }
            });
        };
        
        reader.readAsArrayBuffer(blob);
    
    } else {
            console.log('Received blob is not in the expected format or is empty');
            console.log('Blob size: ', blob.size );
            console.log('Blob type: ', blob.type );
        }    
    }
});
           */
            
        
           // recorder.startRecording(); 
            
    
        })
            .catch(function(err) {
    
                console.log('Failed to get microphone access', err);
        });
        
        
        
    } else {
     
      console.log('Not checked');
    
        myvad.pause()
        
        if(recorder != null) {
        
            recorder.stopRecording(); 
        
            recorder = null;
        
        }
        
        
        
    }
  });
});        
       
    
let debounceTimer;
    
function playSound() {
    const audio = new Audio('/sounds/dingsound.mp3');
    audio.play();
}
    
function handleEvent(event, threshold = 0.2, debounceTime = 1000){
        
    let score = event.detail;
    
    console.log('Hey Haley Score: ', score);
    
    if (debounceTimer) return;
  
    if (score > threshold) {
        playSound();
        debounceTimer = setTimeout(() => {
            clearTimeout(debounceTimer);
            debounceTimer = null;
        }, debounceTime);
    }
}


window.addEventListener('wakeWordEvent', handleEvent);

    
    
    
    
  </script>  

    <script src="flat-ui/js/bootstrap.min.js"></script>
    <script src="common-files/js/modernizr.custom.js"></script>
    <script src="common-files/js/page-transitions.js"></script>
    <script src="common-files/js/jquery.backgroundvideo.min.js"></script>
    <script src="common-files/js/froogaloop.min.js"></script>
    <script src="common-files/js/jquery.scrollTo-1.4.3.1-min.js"></script>
    <script src="common-files/js/startup-kit.js"></script>
    
  </body>
</html>
